{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIxhKkVoN17+cySbHqe1y8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaoEhsanElahi/Parallel_Processing/blob/main/matrix_multiplication_cu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y9TU-ozqax9K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJfzx1hRVdRW",
        "outputId": "335413e3-2f04-4100-c28e-1dbc416cee5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9gl0_yev\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9gl0_yev\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4293 sha256=acea591b9f66104dcde38286939e22293e34b4bc011673ab6bad8b5cee47a3bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nmioro7h/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs4r0phvatf1",
        "outputId": "22561f3b-688c-43e8-98ee-d325282c665d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task1\n",
        "Objective: Implement a CUDA kernel to perform matrix multiplication using shared memory to optimize memory access.\n",
        "###Requirements:\n",
        "\n",
        "1. Use a 2D grid of blocks and a 2D arrangement of threads within each block.\n",
        "2. Utilize shared memory to cache portions of input matrices for faster access.\n",
        "3. Handle matrices of arbitrary size (consider matrices A, B, and C).\n",
        "5. Example: Consider two matrices A and B,\n",
        "where:  \n",
        "        Matrix A: [1 2 3] [4 5 6] [7 8 9]\n",
        "        Matrix B: [91 512 52] [−5 21 5] [−21 52 21]\n",
        "###Tasks :\n",
        "1. Write a CUDA kernel to perform matrix multiplication using shared memory.\n",
        "2. Use the provided matrices A and B for testing. (you have to do this on nxn matrix so that is the main task).\n",
        "3. Compare the results obtained from the GPU with the CPU (serial) implementation to verify correctness.\n",
        "4. Also compute the results of using global and shared memory and their time difference.\n",
        "5. Measure and compare the execution time between the GPU and CPU implementations."
      ],
      "metadata": {
        "id": "Ri17URw4Wpyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "#include <cuda_profiler_api.h>\n",
        "\n",
        "__global__ void matrixMultiplicationKernel(float* A, float* B, float* C, int N) {\n",
        "    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    float Cvalue = 0.0;\n",
        "    for (int k = 0; k < N; ++k)\n",
        "        Cvalue += A[Row * N + k] * B[k * N + Col];\n",
        "\n",
        "    C[Row * N + Col] = Cvalue;\n",
        "}\n",
        "\n",
        "void matrixMulCPU(float* A, float* B, float* C, int N) {\n",
        "    for (int i = 0; i < N; i++)\n",
        "        for (int j = 0; j < N; j++)\n",
        "            for (int k = 0; k < N; k++)\n",
        "                C[i * N + j] += A[i * N + k] * B[k * N + j];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 4; //size of nxn matrix\n",
        "    const int size = N * N * sizeof(float);\n",
        "\n",
        "    float *h_A, *h_B, *h_C_CPU, *h_C_GPU;\n",
        "    h_A = (float*)malloc(size);\n",
        "    h_B = (float*)malloc(size);\n",
        "    h_C_CPU = (float*)malloc(size);\n",
        "    h_C_GPU = (float*)malloc(size);\n",
        "\n",
        "    // initialize the matrices h_A and h_B\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = rand() % 100;\n",
        "        h_B[i] = rand() % 100;\n",
        "    }\n",
        "    // Print Matrix A and B\n",
        "    printf(\"\\nMatrix A:\\n\");\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            printf(\"%f \", h_A[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    std::cout << std::endl << \"Matrix B:\" << std::endl;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            printf(\"%f \", h_B[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    float cpu_time_used = 0.0;\n",
        "    clock_t start_cpu, end_cpu;\n",
        "    start_cpu = clock();\n",
        "    matrixMulCPU(h_A, h_B, h_C_CPU, N);\n",
        "    end_cpu = clock();\n",
        "    cpu_time_used = ((float) (end_cpu - start_cpu)) / CLOCKS_PER_SEC;\n",
        "\n",
        "    std::cout << \"\\nMatrix C (BY CPU):\\n\";\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            std::cout << h_C_CPU[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "    printf(\"\\nCPU time: %f s\\n\", cpu_time_used);\n",
        "\n",
        "    // Allocate memory on the GPU\n",
        "    float *d_A, *d_B, *d_C, gpu_time;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 blockDim(16, 16);\n",
        "    dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matrixMultiplicationKernel<<<gridDim, blockDim>>>(d_A, d_B, d_C, N);\n",
        "    cudaMemcpy(h_C_GPU, d_C, size, cudaMemcpyDeviceToHost);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    std::cout  << \"\\nMatrix C (BY CUDA):\\n\";\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            printf(\"%f \", h_C_GPU[i * N + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    cudaEventElapsedTime(&gpu_time, start, stop);\n",
        "    printf(\"\\nGPU time: %f ms\\n\", gpu_time);\n",
        "\n",
        "\n",
        "\n",
        "    // Compare CPU and GPU results\n",
        "    int i, j, k;\n",
        "    int difference = 0;\n",
        "    for (i = 0; i < N; i++)\n",
        "        for (j = 0; j < N; j++)\n",
        "            difference += fabs(h_C_CPU[i * N + j] - h_C_GPU[i * N + j]);\n",
        "    if (difference > 1e-5) {\n",
        "        printf(\"\\nCPU and GPU results are different\\n\");\n",
        "    } else {\n",
        "        printf(\"\\nMatrices are equal\\n\");\n",
        "    }\n",
        "\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C_CPU);\n",
        "    free(h_C_GPU);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeLd7PjCdf5Z",
        "outputId": "563cb803-c0ed-4f93-d849-b3eacb49b66a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matrix A:\n",
            "83.000000 77.000000 93.000000 86.000000 \n",
            "49.000000 62.000000 90.000000 63.000000 \n",
            "40.000000 72.000000 11.000000 67.000000 \n",
            "82.000000 62.000000 67.000000 29.000000 \n",
            "\n",
            "Matrix B:\n",
            "86.000000 15.000000 35.000000 92.000000 \n",
            "21.000000 27.000000 59.000000 26.000000 \n",
            "26.000000 36.000000 68.000000 29.000000 \n",
            "30.000000 23.000000 35.000000 2.000000 \n",
            "\n",
            "Matrix C (BY CPU):\n",
            "13753 8650 16782 12507 \n",
            "9746 7098 13698 8856 \n",
            "7248 4481 8741 6005 \n",
            "10966 5983 12099 11157 \n",
            "\n",
            "CPU time: 0.000001 s\n",
            "\n",
            "Matrix C (BY CUDA):\n",
            "13753.000000 8650.000000 16782.000000 12507.000000 \n",
            "6535.000000 7152.000000 13388.000000 4577.000000 \n",
            "4468.000000 4759.000000 8339.000000 2561.000000 \n",
            "2490.000000 1909.000000 2905.000000 166.000000 \n",
            "\n",
            "GPU time: 0.243904 ms\n",
            "\n",
            "CPU and GPU results are different\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-QVecxJRfscw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}